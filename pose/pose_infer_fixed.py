"""
RK3576 YOLOv8 Pose å§¿æ€ä¼°è®¡æŽ¨ç†è„šæœ¬
å‚è€ƒ: https://github.com/airockchip/rknn_model_zoo/tree/master/examples/yolov8_pose
åŸºäºŽ rk3576_infer_fixed.py æ”¹é€ 
"""

import cv2
import numpy as np
from rknnlite.api import RKNNLite

# å‚æ•°è®¾ç½®
OBJ_THRESH = 0.5  # å§¿æ€ä¼°è®¡ç½®ä¿¡åº¦é˜ˆå€¼
NMS_THRESH = 0.4  # NMSé˜ˆå€¼
IMG_SIZE = (640, 640)

# COCOå§¿æ€ä¼°è®¡ç±»åˆ«ï¼ˆåªæœ‰personï¼‰
CLASSES = ('person',)

# COCO 17ä¸ªå…³é”®ç‚¹åç§°
KEYPOINT_NAMES = [
    'nose',           # 0
    'left_eye',       # 1
    'right_eye',      # 2
    'left_ear',       # 3
    'right_ear',      # 4
    'left_shoulder',  # 5
    'right_shoulder', # 6
    'left_elbow',     # 7
    'right_elbow',    # 8
    'left_wrist',     # 9
    'right_wrist',    # 10
    'left_hip',       # 11
    'right_hip',      # 12
    'left_knee',      # 13
    'right_knee',     # 14
    'left_ankle',     # 15
    'right_ankle'     # 16
]

# å§¿æ€è°ƒè‰²æ¿
pose_palette = np.array([
    [255, 128, 0], [255, 153, 51], [255, 178, 102], [230, 230, 0], [255, 153, 255],
    [153, 204, 255], [255, 102, 255], [255, 51, 255], [102, 178, 255], [51, 153, 255],
    [255, 153, 153], [255, 102, 102], [255, 51, 51], [153, 255, 153], [102, 255, 102],
    [51, 255, 51], [0, 255, 0], [0, 0, 255], [255, 0, 0], [255, 255, 255]
], dtype=np.uint8)

# å…³é”®ç‚¹é¢œè‰²
kpt_color = pose_palette[[16, 16, 16, 16, 16, 0, 0, 0, 0, 0, 0, 9, 9, 9, 9, 9, 9]]

# éª¨æž¶è¿žæŽ¥ï¼ˆå…³é”®ç‚¹ç´¢å¼•å¯¹ï¼‰
skeleton = [
    [16, 14], [14, 12], [17, 15], [15, 13], [12, 13], [6, 12], [7, 13],
    [6, 7], [6, 8], [7, 9], [8, 10], [9, 11], [2, 3], [1, 2], [1, 3],
    [2, 4], [3, 5], [4, 6], [5, 7]
]

# éª¨æž¶é¢œè‰²
limb_color = pose_palette[[9, 9, 9, 9, 7, 7, 7, 0, 0, 0, 0, 0, 16, 16, 16, 16, 16, 16, 16]]


def sigmoid(x):
    """Sigmoidæ¿€æ´»å‡½æ•°"""
    return 1 / (1 + np.exp(-x))


def softmax(x, axis=-1):
    """Softmaxå‡½æ•°"""
    exp_x = np.exp(x - np.max(x, axis=axis, keepdims=True))
    return exp_x / np.sum(exp_x, axis=axis, keepdims=True)


def process_output_branch(output, keypoints, kp_offset, model_w, model_h, stride):
    """
    å¤„ç†å•ä¸ªè¾“å‡ºåˆ†æ”¯

    Args:
        output: å•ä¸ªåˆ†æ”¯è¾“å‡º (1, 65, H, W)
        keypoints: æ‰€æœ‰å…³é”®ç‚¹æ•°æ® (1, 17, 3, 8400)
        kp_offset: å…³é”®ç‚¹ç´¢å¼•åç§» (0/6400/8000)
        model_w, model_h: ç‰¹å¾å›¾å°ºå¯¸
        stride: æ­¥é•¿

    Returns:
        list of DetectBox
    """
    boxes = []

    # åˆ†ç¦»è¾¹ç•Œæ¡†å’Œç½®ä¿¡åº¦
    xywh = output[:, :64, :]  # (1, 64, H*W)
    conf = sigmoid(output[:, 64:, :])  # (1, 1, H*W)

    # å±•å¹³ç‰¹å¾å›¾
    xywh = xywh.reshape(1, 64, -1)  # (1, 64, H*W)
    conf = conf.reshape(1, -1)  # (1, H*W)

    # éåŽ†æ‰€æœ‰ç½‘æ ¼ç‚¹
    for i in range(model_h * model_w):
        score = conf[0, i]

        if score > OBJ_THRESH:
            # DFLè§£ç 
            xywh_i = xywh[0, :, i].reshape(1, 4, 16, 1)
            data = np.array([i for i in range(16)]).reshape(1, 1, 16, 1)

            # Softmax + æœŸæœ›å€¼
            xywh_i = softmax(xywh_i, 2)
            xywh_i = np.multiply(data, xywh_i)
            xywh_i = np.sum(xywh_i, axis=2, keepdims=True).reshape(-1)

            # è®¡ç®—ç½‘æ ¼åæ ‡
            h = i // model_w
            w = i % model_w

            # è®¡ç®—è¾¹ç•Œæ¡†ï¼ˆä¸­å¿ƒç‚¹æ ¼å¼ï¼‰
            xywh_temp = xywh_i.copy()
            xywh_temp[0] = (w + 0.5) - xywh_i[0]
            xywh_temp[1] = (h + 0.5) - xywh_i[1]
            xywh_temp[2] = (w + 0.5) + xywh_i[2]
            xywh_temp[3] = (h + 0.5) + xywh_i[3]

            # è½¬æ¢ä¸ºxywhæ ¼å¼
            xywh_i[0] = ((xywh_temp[0] + xywh_temp[2]) / 2)
            xywh_i[1] = ((xywh_temp[1] + xywh_temp[3]) / 2)
            xywh_i[2] = (xywh_temp[2] - xywh_temp[0])
            xywh_i[3] = (xywh_temp[3] - xywh_temp[1])

            # åº”ç”¨æ­¥é•¿
            xywh_i = xywh_i * stride

            # è½¬æ¢ä¸ºxyxyæ ¼å¼
            xmin = (xywh_i[0] - xywh_i[2] / 2)
            ymin = (xywh_i[1] - xywh_i[3] / 2)
            xmax = (xywh_i[0] + xywh_i[2] / 2)
            ymax = (xywh_i[1] + xywh_i[3] / 2)

            # æå–å…³é”®ç‚¹ï¼škeypoints shape is (1, 17, 3, 8400)
            # è®¡ç®—å…¨å±€ç´¢å¼•
            global_i = i + kp_offset
            # æå–è¯¥ç½‘æ ¼ç‚¹çš„æ‰€æœ‰17ä¸ªå…³é”®ç‚¹
            # keypoints[:, :, :, global_i] gives (1, 17, 3)
            keypoint = keypoints[:, :, :, global_i].reshape(17, 3)

            boxes.append(DetectBox(0, score, xmin, ymin, xmax, ymax, keypoint))

    return boxes


class DetectBox:
    """æ£€æµ‹ç»“æžœç±»"""
    def __init__(self, classId, score, xmin, ymin, xmax, ymax, keypoint):
        self.classId = classId
        self.score = score
        self.xmin = xmin
        self.ymin = ymin
        self.xmax = xmax
        self.ymax = ymax
        self.keypoint = keypoint


def iou(box1, box2):
    """è®¡ç®—IoU"""
    xmin = max(box1.xmin, box2.xmin)
    ymin = max(box1.ymin, box2.ymin)
    xmax = min(box1.xmax, box2.xmax)
    ymax = min(box1.ymax, box2.ymax)

    inner_width = xmax - xmin
    inner_height = ymax - ymin

    inner_width = inner_width if inner_width > 0 else 0
    inner_height = inner_height if inner_height > 0 else 0

    inner_area = inner_width * inner_height

    area1 = (box1.xmax - box1.xmin) * (box1.ymax - box1.ymin)
    area2 = (box2.xmax - box2.xmin) * (box2.ymax - box2.ymin)

    total = area1 + area2 - inner_area

    return inner_area / total if total > 0 else 0


def nms(boxes):
    """éžæžå¤§å€¼æŠ‘åˆ¶"""
    keep_boxes = []

    # æŒ‰ç½®ä¿¡åº¦æŽ’åº
    sorted_boxes = sorted(boxes, key=lambda x: x.score, reverse=True)

    for i in range(len(sorted_boxes)):
        box1 = sorted_boxes[i]

        if box1.classId != -1:
            keep_boxes.append(box1)

            for j in range(i + 1, len(sorted_boxes)):
                box2 = sorted_boxes[j]

                if box1.classId == box2.classId:
                    if iou(box1, box2) > NMS_THRESH:
                        box2.classId = -1

    return keep_boxes


def post_process(outputs):
    """
    åŽå¤„ç†å‡½æ•°

    Args:
        outputs: æ¨¡åž‹è¾“å‡ºåˆ—è¡¨
            outputs[0-2]: 3ä¸ªå°ºåº¦çš„è¾¹ç•Œæ¡†é¢„æµ‹ (1, 65, H, W)
            outputs[3]: å…³é”®ç‚¹æ•°æ® (1, 17, 3, 8400)

    Returns:
        list of DetectBox
    """
    all_boxes = []
    keypoints = outputs[3]  # (1, 17, 3, 8400)

    # å¤„ç†3ä¸ªå°ºåº¦ï¼ˆP3, P4, P5ï¼‰
    # outputs[0]: P3 (80x80, stride=8)
    # outputs[1]: P4 (40x40, stride=16)
    # outputs[2]: P5 (20x20, stride=32)

    # è®¡ç®—æ¯ä¸ªåˆ†æ”¯çš„å…³é”®ç‚¹ç´¢å¼•åç§»
    # 8400 = 80*80 + 40*40 + 20*20 = 6400 + 1600 + 400
    # P3 offset = 0
    # P4 offset = 6400
    # P5 offset = 6400 + 1600 = 8000
    strides = [8, 16, 32]
    kp_offsets = [0, 6400, 8000]

    for i, output in enumerate(outputs[:3]):
        model_h, model_w = output.shape[2], output.shape[3]
        boxes = process_output_branch(
            output, keypoints, kp_offsets[i], model_w, model_h, strides[i]
        )
        all_boxes.extend(boxes)

    # NMS
    final_boxes = nms(all_boxes)

    return final_boxes


def draw_pose(img, keypoints, skeleton_color=None):
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶å§¿æ€éª¨æž¶å’Œå¤´éƒ¨åœ†åœˆ

    Args:
        img: å›¾åƒ
        keypoints: å…³é”®ç‚¹æ•°ç»„ (17, 3) - [x, y, confidence]
        skeleton_color: éª¨æž¶é¢œè‰²ï¼Œå¦‚æžœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤é¢œè‰²
    """
    # ç»˜åˆ¶å…³é”®ç‚¹
    for k, keypoint in enumerate(keypoints):
        x, y, conf = keypoint
        color_k = [int(x) for x in kpt_color[k]]

        if x != 0 and y != 0 and conf > 0.3:  # ç½®ä¿¡åº¦é˜ˆå€¼
            cv2.circle(img, (int(x), int(y)), 5, color_k, -1, lineType=cv2.LINE_AA)

    # ç»˜åˆ¶éª¨æž¶
    for k, sk in enumerate(skeleton):
        pos1 = (int(keypoints[(sk[0] - 1), 0]), int(keypoints[(sk[0] - 1), 1]))
        pos2 = (int(keypoints[(sk[1] - 1), 0]), int(keypoints[(sk[1] - 1), 1]))

        conf1 = keypoints[(sk[0] - 1), 2]
        conf2 = keypoints[(sk[1] - 1), 2]

        if pos1[0] == 0 or pos1[1] == 0 or pos2[0] == 0 or pos2[1] == 0:
            continue

        if conf1 > 0.3 and conf2 > 0.3:
            if skeleton_color is None:
                color = [int(x) for x in limb_color[k]]
            else:
                color = skeleton_color
            cv2.line(img, pos1, pos2, color, thickness=2, lineType=cv2.LINE_AA)


def detect_head_circle(keypoints, bbox):
    """
    æ£€æµ‹å¤´éƒ¨ä½ç½®å¹¶ç»˜åˆ¶åœ†åœˆ

    Args:
        keypoints: å…³é”®ç‚¹æ•°ç»„ (17, 3)
        bbox: è¾¹ç•Œæ¡† [xmin, ymin, xmax, ymax]

    Returns:
        head_center: å¤´éƒ¨ä¸­å¿ƒåæ ‡ (x, y) æˆ– None
        head_radius: å¤´éƒ¨åŠå¾„ æˆ– None
    """
    # å¤´éƒ¨ç›¸å…³å…³é”®ç‚¹ç´¢å¼•ï¼š0=nose, 1=left_eye, 2=right_eye, 3=left_ear, 4=right_ear
    head_kpt_indices = [0, 1, 2, 3, 4]

    # æ”¶é›†å¯è§çš„å¤´éƒ¨å…³é”®ç‚¹
    visible_head_pts = []
    for idx in head_kpt_indices:
        x, y, conf = keypoints[idx]
        if x > 0 and y > 0 and conf > 0.3:  # ç½®ä¿¡åº¦é˜ˆå€¼
            visible_head_pts.append((x, y))

    if len(visible_head_pts) == 0:
        return None, None

    # æ–¹æ³•1ï¼šåŸºäºŽå¯è§å…³é”®ç‚¹è®¡ç®—å¤´éƒ¨ä¸­å¿ƒ
    head_center_x = sum([pt[0] for pt in visible_head_pts]) / len(visible_head_pts)
    head_center_y = sum([pt[1] for pt in visible_head_pts]) / len(visible_head_pts)

    # æ–¹æ³•2ï¼šä¼°ç®—å¤´éƒ¨åŠå¾„
    # å¦‚æžœæœ‰è€³æœµï¼Œä½¿ç”¨è€³æœµé—´è·ï¼›å¦åˆ™ä½¿ç”¨çœ¼ç›é—´è·
    left_ear = keypoints[3]
    right_ear = keypoints[4]
    left_eye = keypoints[1]
    right_eye = keypoints[2]

    if left_ear[0] > 0 and right_ear[0] > 0 and left_ear[2] > 0.3 and right_ear[2] > 0.3:
        # ä½¿ç”¨è€³æœµé—´è·ï¼Œå¤´éƒ¨å®½åº¦çº¦ä¸ºè€³æœµé—´è·çš„1.2å€
        ear_dist = abs(right_ear[0] - left_ear[0])
        head_radius = int(ear_dist * 0.9)  # åŠå¾„çº¦ä¸ºè€³æœµé—´è·çš„90% (å¢žå¤§)
    elif left_eye[0] > 0 and right_eye[0] > 0 and left_eye[2] > 0.3 and right_eye[2] > 0.3:
        # ä½¿ç”¨çœ¼ç›é—´è·ï¼Œå¤´éƒ¨å®½åº¦çº¦ä¸ºçœ¼ç›é—´è·çš„3å€
        eye_dist = abs(right_eye[0] - left_eye[0])
        head_radius = int(eye_dist * 2.2)  # åŠå¾„çº¦ä¸ºçœ¼ç›é—´è·çš„220% (å¢žå¤§)
    else:
        # åŸºäºŽè¾¹ç•Œæ¡†ä¼°ç®—ï¼ˆå¤´éƒ¨é€šå¸¸å äººè„¸å®½åº¦çš„çº¦15-20%ï¼‰
        bbox_width = bbox[2] - bbox[0]
        head_radius = int(bbox_width * 0.18)  # å¢žå¤§ç³»æ•°åˆ°18%

    # ç¡®ä¿åŠå¾„åœ¨åˆç†èŒƒå›´å†…
    head_radius = max(25, min(head_radius, 150))  # æœ€å°25ï¼Œæœ€å¤§150

    return (head_center_x, head_center_y), head_radius


def draw_head_circle(img, head_center, head_radius, color=(255, 0, 0), thickness=3):
    """
    åœ¨å›¾åƒä¸Šç»˜åˆ¶å¤´éƒ¨åœ†åœˆ

    Args:
        img: å›¾åƒ
        head_center: å¤´éƒ¨ä¸­å¿ƒ (x, y)
        head_radius: å¤´éƒ¨åŠå¾„
        color: åœ†åœˆé¢œè‰² (B, G, R)
        thickness: çº¿æ¡ç²—ç»†
    """
    if head_center is not None and head_radius is not None:
        cv2.circle(img, (int(head_center[0]), int(head_center[1])),
                  head_radius, color, thickness, lineType=cv2.LINE_AA)
        # ç»˜åˆ¶ä¸­å¿ƒç‚¹
        cv2.circle(img, (int(head_center[0]), int(head_center[1])),
                  3, (0, 255, 0), -1, lineType=cv2.LINE_AA)


class YOLOv8PoseRK3576:
    """YOLOv8å§¿æ€ä¼°è®¡ RK3576æŽ¨ç†ç±»"""

    def __init__(self, rknn_model='yolov8_pose.rknn'):
        """åˆå§‹åŒ– RKNN æ¨¡åž‹"""
        self.rknn_lite = RKNNLite()
        print(f'--> Loading RKNN model: {rknn_model}')
        ret = self.rknn_lite.load_rknn(rknn_model)
        if ret != 0:
            print('Load RKNN model failed!')
            exit(-1)

        print('--> Init runtime environment')
        ret = self.rknn_lite.init_runtime()
        if ret != 0:
            print('Init runtime failed!')
            exit(-1)

        print('Model loaded successfully!')

    def infer(self, img_path):
        """
        æŽ¨ç†ä¸»å‡½æ•°

        Args:
            img_path: è¾“å…¥å›¾åƒè·¯å¾„

        Returns:
            æ£€æµ‹ç»“æžœåˆ—è¡¨
        """
        img = cv2.imread(img_path)
        if img is None:
            print(f'Failed to load image: {img_path}')
            return None

        img_h, img_w = img.shape[:2]

        print(f"\n{'='*60}")
        print(f"Image: {img_path}")
        print(f"Size: {img_w} x {img_h} pixels")
        print(f"{'='*60}")

        # Letterboxé¢„å¤„ç†ï¼ˆä¸Žæ£€æµ‹æ¨¡åž‹ç›¸åŒï¼‰
        shape = (img_h, img_w)
        scale = min(IMG_SIZE[0] / shape[0], IMG_SIZE[1] / shape[1])
        new_unpad = (int(round(shape[1] * scale)), int(round(shape[0] * scale)))
        dw_total, dh_total = IMG_SIZE[1] - new_unpad[0], IMG_SIZE[0] - new_unpad[1]
        dw = dw_total / 2
        dh = dh_total / 2

        if shape[::-1] != new_unpad:
            resized = cv2.resize(img, new_unpad, interpolation=cv2.INTER_LINEAR)
        else:
            resized = img

        top, bottom = int(round(dh - 0.1)), int(round(dh + 0.1))
        left, right = int(round(dw - 0.1)), int(round(dw + 0.1))
        img_padded = cv2.copyMakeBorder(resized, top, bottom, left, right,
                                        cv2.BORDER_CONSTANT, value=(0, 0, 0))

        # BGR -> RGB
        img_rgb = cv2.cvtColor(img_padded, cv2.COLOR_BGR2RGB)

        # è½¬æ¢ä¸ºRKNNæ ¼å¼
        input_data = np.expand_dims(img_rgb, axis=0)

        print(f'è¾“å…¥ shape: {input_data.shape}, dtype={input_data.dtype}')
        print('--> Running inference...')

        # æŽ¨ç†
        outputs = self.rknn_lite.inference(inputs=[input_data])

        print('--> Post-processing...')
        boxes = post_process(outputs)

        if not boxes:
            print("\nâŒ No persons detected!")
            return None

        print(f"\nâœ… Detected {len(boxes)} person(s):\n")

        # åæ ‡æ˜ å°„å›žåŽŸå›¾
        results = []
        for i, box in enumerate(boxes):
            # æ˜ å°„è¾¹ç•Œæ¡†
            box.xmin = (box.xmin - dw) / scale
            box.ymin = (box.ymin - dh) / scale
            box.xmax = (box.xmax - dw) / scale
            box.ymax = (box.ymax - dh) / scale

            # é™åˆ¶åœ¨å›¾åƒèŒƒå›´å†…
            box.xmin = max(0, min(box.xmin, img_w))
            box.ymin = max(0, min(box.ymin, img_h))
            box.xmax = max(0, min(box.xmax, img_w))
            box.ymax = max(0, min(box.ymax, img_h))

            # æ˜ å°„å…³é”®ç‚¹
            kp = box.keypoint.reshape(-1, 3)  # (17, 3)
            kp[..., 0] = (kp[..., 0] - dw) / scale  # xåæ ‡
            kp[..., 1] = (kp[..., 1] - dh) / scale  # yåæ ‡
            kp[..., 0] = np.clip(kp[..., 0], 0, img_w)
            kp[..., 1] = np.clip(kp[..., 1], 0, img_h)

            print(f"Person {i+1}:")
            print(f"  Confidence: {box.score:.2f}")
            print(f"  BBox: ({box.xmin:.1f}, {box.ymin:.1f}) to ({box.xmax:.1f}, {box.ymax:.1f})")

            # ç»Ÿè®¡å¯è§å…³é”®ç‚¹
            visible_kpts = np.sum(kp[:, 2] > 0.3)
            print(f"  Visible keypoints: {visible_kpts}/17")

            # ç»˜åˆ¶è¾¹ç•Œæ¡†
            cv2.rectangle(img, (int(box.xmin), int(box.ymin)),
                         (int(box.xmax), int(box.ymax)), (0, 255, 0), 2)
            cv2.putText(img, f'person {box.score:.2f}',
                       (int(box.xmin), int(box.ymin) - 10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)

            # ç»˜åˆ¶å§¿æ€
            draw_pose(img, kp)

            # æ£€æµ‹å¹¶ç»˜åˆ¶å¤´éƒ¨åœ†åœˆ
            bbox = [box.xmin, box.ymin, box.xmax, box.ymax]
            head_center, head_radius = detect_head_circle(kp, bbox)

            if head_center is not None:
                # ç»˜åˆ¶å¤´éƒ¨åœ†åœˆï¼ˆçº¢è‰²ï¼‰
                draw_head_circle(img, head_center, head_radius, color=(255, 0, 0), thickness=3)

                # è¾“å‡ºå¤´éƒ¨ä¿¡æ¯
                print(f"  ðŸ“ Head center: ({head_center[0]:.1f}, {head_center[1]:.1f}), radius: {head_radius}")
            else:
                print(f"  âš ï¸  Head not detected (insufficient keypoints)")

            results.append({
                'confidence': float(box.score),
                'bbox': [float(box.xmin), float(box.ymin), float(box.xmax), float(box.ymax)],
                'keypoints': kp.tolist(),  # (17, 3) -> list
                'head_center': [float(head_center[0]), float(head_center[1])] if head_center else None,
                'head_radius': head_radius
            })

            print()

        # ä¿å­˜ç»“æžœ
        output_path = 'result_pose_rk3576.jpg'
        cv2.imwrite(output_path, img)
        print(f"Result saved to: {output_path}")

        return results

    def __del__(self):
        if hasattr(self, 'rknn_lite'):
            self.rknn_lite.release()


def main():
    import sys

    model = YOLOv8PoseRK3576('yolov8_pose.rknn')

    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    img_path = sys.argv[1] if len(sys.argv) > 1 else 'bus.jpg'

    model.infer(img_path)
    del model


if __name__ == '__main__':
    main()
